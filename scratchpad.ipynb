{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a38a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dit import DiT, sample\n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c830e02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DiT(28, 28, patch_size=2, n_classes=11, d=12*16, n_head=12, n_blocks=6)\n",
    "model.load_state_dict(t.load(\"/share/u/wendler/code/mnist/checkpoints/model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78895c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (patch): Patch(\n",
       "    (conv): Conv2d(1, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (te): NumEmbedding()\n",
       "  (ce): Embedding(11, 192)\n",
       "  (act): SiLU()\n",
       "  (blocks): ModuleList(\n",
       "    (0-5): 6 x DiTBlock(\n",
       "      (norm1): RMSNorm()\n",
       "      (attn): Attention(\n",
       "        (QKV): Linear(in_features=192, out_features=576, bias=False)\n",
       "        (O): Linear(in_features=192, out_features=192, bias=False)\n",
       "        (normq): RMSNorm()\n",
       "        (normk): RMSNorm()\n",
       "      )\n",
       "      (norm2): RMSNorm()\n",
       "      (mlp): MLP(\n",
       "        (up): Linear(in_features=192, out_features=384, bias=False)\n",
       "        (gate): Linear(in_features=192, out_features=384, bias=False)\n",
       "        (down): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (modulate): Linear(in_features=192, out_features=1152, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (modulate): Linear(in_features=192, out_features=384, bias=True)\n",
       "  (unpatch): UnPatch(\n",
       "    (up): Linear(in_features=192, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3782ee92",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DiT' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m z = t.randn(\u001b[32m100\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m28\u001b[39m, \u001b[32m28\u001b[39m, dtype=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m, device=model.device)\n\u001b[32m      2\u001b[39m y = t.ones(\u001b[32m100\u001b[39m, dtype=t.long, device=model.device)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m11\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/mnist/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'DiT' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "z = t.randn(100, 1, 28, 28, dtype=model.dtype, device=model.device)\n",
    "y = t.ones(100, dtype=t.long, device=model.device)\n",
    "for num in range(11):\n",
    "  print(num)\n",
    "  if num > 0:\n",
    "    cfg = 3\n",
    "  else:\n",
    "    cfg = 0\n",
    "  x_pred = sample(model, z, y*0 + num, cfg=cfg, n_steps=30)\n",
    "\n",
    "  fig, axes = plt.subplots(4, 8, figsize=(8, 4))\n",
    "  axes = axes.flatten()\n",
    "\n",
    "  for i in range(32):\n",
    "      img = x_pred[i].squeeze().detach().cpu().clamp(-1, 1)\n",
    "      img = (img + 1) / 2  # map back to [0,1]\n",
    "\n",
    "      axes[i].imshow(img, cmap='gray')\n",
    "      axes[i].axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
